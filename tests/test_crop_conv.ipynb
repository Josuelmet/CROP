{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHQVtPCnDI9n",
        "outputId": "9aff208f-60b3-4aa0-c16b-3f57c27afd60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CROP'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 88 (delta 28), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (88/88), 665.41 KiB | 4.62 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "#@title Download CROP if necessary\n",
        "\n",
        "import os\n",
        "import sys\n",
        "if 'crop.py' not in os.listdir('..'):\n",
        "    !git clone https://github.com/Josuelmet/CROP.git\n",
        "    sys.path.append('./CROP')\n",
        "else:\n",
        "    sys.path.append('..')\n",
        "\n",
        "from crop import *\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing conv. CROP on a random high-dimensional model"
      ],
      "metadata": {
        "id": "2fLzkqOgKXPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "model = torchvision.models.vgg16()\n",
        "\n",
        "# We have to convert to Sequential to add the Flatten layer\n",
        "# because casting replaces the model's original forward() function\n",
        "model = nn.Sequential(OrderedDict([\n",
        "    (\"features\",   model.features),\n",
        "    (\"avgpool\",    model.avgpool),\n",
        "    (\"flatten\",    nn.Flatten(1)),\n",
        "    (\"classifier\", model.classifier)\n",
        "]))\n",
        "\n",
        "# Optional:\n",
        "# Converting MaxPool to AvgPool\n",
        "#for i,m in enumerate(model.features._modules.values()):\n",
        "#    if isinstance(m, nn.MaxPool2d):\n",
        "#        model.features[i] = nn.AvgPool2d(**{k:v for k,v in vars(m).items() if k in nn.AvgPool2d.__constants__})\n",
        "\n",
        "for m in model.modules():\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        with torch.no_grad():\n",
        "            m.weight.data = torch.randn_like(m.weight)\n",
        "            m.bias.data = torch.randn_like(m.bias)"
      ],
      "metadata": {
        "id": "GxvleyNldtbD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConstrainedSequential.cast(model.eval(), constrain_last=True) # THE EVAL IS IMPORTANT B/C OF DROPOUT"
      ],
      "metadata": {
        "id": "2zp0rzlWJHJA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R, V = 4, 10\n",
        "c = torch.randn(R, V, 3, 32, 32)\n",
        "x = torch.randn(1, 3, 32, 32)"
      ],
      "metadata": {
        "id": "1Gzz2kpcYJPu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(c.reshape((R*V,) + c.shape[2:]), c)\n",
        "out = out.reshape((R,V) + out.shape[1:])"
      ],
      "metadata": {
        "id": "pks8X6iFJD3k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConstrainedSequential.uncast(model)"
      ],
      "metadata": {
        "id": "vL-0GTCITjkj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On these pretrained VGG networks, sometimes\n",
        "\n",
        "for each_constraint in c:\n",
        "    flags, unmatched_act, acts = check_layerwise_signs(model, each_constraint)\n",
        "\n",
        "    # Index up to :-1 because the last layer's signs do not need to agree.\n",
        "    print('All signs agree', all(flags[:-1]))\n",
        "    print('Abs sum of activations that disagree',sum(unmatched_act[:-1]))\n",
        "\n",
        "    #break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpFWKK8kfCJN",
        "outputId": "2c0feac9-ed8f-40a9-bf89-e42ca9fca700"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All signs agree True\n",
            "Abs sum of activations that disagree tensor(0.)\n",
            "All signs agree True\n",
            "Abs sum of activations that disagree tensor(0.)\n",
            "All signs agree True\n",
            "Abs sum of activations that disagree tensor(0.)\n",
            "All signs agree True\n",
            "Abs sum of activations that disagree tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, a in enumerate(acts):\n",
        "    s = a.sign().sum(0)\n",
        "    if a.ndim > 2:\n",
        "        s = s.sum((1, 2))\n",
        "    print(f'{i}:\\t{(s % s.max()).abs().sum() == 0}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3oi_BzCVL-f",
        "outputId": "d970eb72-e35a-427c-d811-d2a753603229"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tTrue\n",
            "1:\tTrue\n",
            "2:\tTrue\n",
            "3:\tTrue\n",
            "4:\tTrue\n",
            "5:\tTrue\n",
            "6:\tTrue\n",
            "7:\tTrue\n",
            "8:\tTrue\n",
            "9:\tTrue\n",
            "10:\tTrue\n",
            "11:\tTrue\n",
            "12:\tTrue\n",
            "13:\tTrue\n",
            "14:\tTrue\n",
            "15:\tTrue\n",
            "16:\tTrue\n",
            "17:\tTrue\n",
            "18:\tTrue\n",
            "19:\tTrue\n",
            "20:\tTrue\n",
            "21:\tTrue\n",
            "22:\tTrue\n",
            "23:\tTrue\n",
            "24:\tTrue\n",
            "25:\tTrue\n",
            "26:\tTrue\n",
            "27:\tTrue\n",
            "28:\tTrue\n",
            "29:\tTrue\n",
            "30:\tTrue\n",
            "31:\tTrue\n",
            "32:\tTrue\n",
            "33:\tTrue\n",
            "34:\tTrue\n",
            "35:\tTrue\n",
            "36:\tTrue\n",
            "37:\tTrue\n",
            "38:\tTrue\n",
            "39:\tTrue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Line-by-line testing"
      ],
      "metadata": {
        "id": "ltSmGJqVEZ_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.vgg16()\n",
        "\n",
        "m = model.features[0]\n",
        "with torch.no_grad():\n",
        "    m.weight += torch.randn_like(m.weight)\n",
        "x = torch.randn(6, 3, 32, 32)\n",
        "R, V = (3, 2)\n",
        "assert R * V == x.shape[0]\n",
        "\n",
        "force_linearity = True\n",
        "\n",
        "h = m(x)"
      ],
      "metadata": {
        "id": "XBy1FdD4EY_6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of channels\n",
        "C = h.shape[1]\n",
        "\n",
        "# Isolate the preactivations belonging to constraint region vertices\n",
        "h_c = torch.clone(h[-R * V:])\n",
        "# Make the first dimension the channel dimension\n",
        "h_c = h_c.transpose(0, 1)\n",
        "# Flatten all but the first two dimensions\n",
        "h_c_flat = h_c.reshape((C, R, -1))\n",
        "\n",
        "\n",
        "# The bias applied to each channel's output is a scalar.\n",
        "# Therefore, we need to take the aggregate sum of *all* entry signs from\n",
        "# *all* vertices of *each* constraint region for *each* channel.\n",
        "# We do this via sign(h_c_flat).sum(2), which returns a (C x R) matrix.\n",
        "# Taking the sign() of that matrix indicates the majority sign of each\n",
        "# channel of each constraint region.\n",
        "regionwise_majority = sign(sign(h_c_flat).sum(2))\n",
        "regionwise_majority"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDngmY1SErTK",
        "outputId": "3fa131da-9d86-4a42-eeff-5c9bcbd5cf97"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [-1., -1., -1.],\n",
              "        [ 1.,  1., -1.],\n",
              "        [-1., -1.,  1.],\n",
              "        [-1.,  1.,  1.],\n",
              "        [ 1., -1., -1.],\n",
              "        [-1., -1., -1.],\n",
              "        [-1.,  1.,  1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [ 1., -1.,  1.],\n",
              "        [ 1.,  1., -1.],\n",
              "        [-1., -1., -1.],\n",
              "        [ 1., -1., -1.],\n",
              "        [ 1., -1.,  1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [-1., -1., -1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [ 1., -1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [-1., -1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [-1.,  1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [ 1., -1.,  1.],\n",
              "        [ 1., -1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [ 1.,  1., -1.],\n",
              "        [ 1., -1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [-1., -1.,  1.],\n",
              "        [ 1.,  1., -1.],\n",
              "        [-1., -1., -1.],\n",
              "        [-1.,  1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [ 1., -1., -1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [ 1., -1.,  1.],\n",
              "        [-1., -1.,  1.],\n",
              "        [-1., -1., -1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [-1.,  1., -1.],\n",
              "        [-1.,  1.,  1.],\n",
              "        [ 1.,  1., -1.],\n",
              "        [ 1., -1., -1.],\n",
              "        [ 1., -1., -1.],\n",
              "        [-1., -1., -1.]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# regionwise_majority is now a (C x R) binary tensor with values {-1, 1}.\n",
        "# We compute desired_signs (a length-C vector) via majority vote among regions\n",
        "desired_signs = sign(regionwise_majority.sum(1))\n",
        "desired_signs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRIQwoJjEuBi",
        "outputId": "30b7989a-7ab0-4dde-cc3b-4b64fa7522d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,\n",
              "         1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1.,\n",
              "         1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
              "        -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,\n",
              "         1.,  1., -1.,  1.,  1., -1., -1., -1.], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we don't need to force linearity in all regions,\n",
        "# then we only need to look at points that are part of the majority-sign coalition.\n",
        "# All other points will be multiplied by zero.\n",
        "if not force_linearity:\n",
        "    h_c_flat *= (regionwise_majority == desired_signs[:, None]).unsqueeze(2)\n",
        "\n",
        "\n",
        "# Calculate extra bias\n",
        "extra_bias = (h_c_flat * desired_signs[:, None, None]).amin((1,2)).clamp(max=0) * desired_signs * (1 + 1e-3)\n",
        "# Reshape extra_bias to be compatible with the shape of h\n",
        "extra_bias = extra_bias.reshape((1, C,) + tuple(torch.ones(h.ndim - 2).to(int)))\n",
        "\n",
        "extra_bias.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXo1oJrqEwKR",
        "outputId": "e72ce379-3624-4d64-f0f5-99303bc4e35a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-19.6577,  14.3502, -22.4661,  15.1722, -19.3050,  17.9165,  25.0987,\n",
              "        -20.9312,  15.7228, -18.6171,  20.3821,  19.0568, -20.1554,  19.4312,\n",
              "        -17.6010, -20.3626,  21.3508,  16.7045, -20.4194, -15.5700,  21.1873,\n",
              "         12.5803, -19.3323, -18.4732,  15.0266,  21.7979,  18.4891,  18.0978,\n",
              "        -17.6602, -17.2189,  22.2625, -20.7817,  19.7589,  21.6744,  13.8114,\n",
              "        -16.2153, -14.2942,  21.4378,  22.4948, -20.2694, -15.6798,  21.7140,\n",
              "         18.1330, -21.3525,  15.1057, -18.7802,  23.1020,  21.9895, -25.5568,\n",
              "        -15.3556, -23.2312,  23.9515,  16.1611, -20.5781,  19.5204,  25.2621,\n",
              "        -18.3033, -19.9708,  19.0404, -21.5399, -16.8333,  19.0248,  14.7314,\n",
              "         15.8933], grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This should be an array of 0s, where each entry represents a channel.\n",
        "(h - extra_bias).sign().sum((0,2,3)).abs() - (h.shape[0] * h.shape[2] * h.shape[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulgs_M1LEyJi",
        "outputId": "3fa6e30a-a077-45e2-a374-3289f66871d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}